{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HwcMbk1XqgpC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbFg_yW7e52i"
      },
      "source": [
        "# ESPResSo 4.2 - Build and Run in Google Colab\n",
        "\n",
        "This notebook installs ESPResSo 4.2 from source, builds it with Python bindings, and runs a basic test simulation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH0mUdnce52l"
      },
      "source": [
        "# Install system and Python dependencies\n",
        "!apt-get update\n",
        "!apt-get install -y cmake g++ libfftw3-dev libhdf5-dev libboost-all-dev openmpi-bin libopenmpi-dev\n",
        "!pip install numpy scipy h5py mpi4py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GRQdg8oe52m"
      },
      "source": [
        "# Clone ESPResSo 4.2 with submodules\n",
        "!git clone --recursive --single-branch -b 4.2 https://github.com/espressomd/espresso.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOXVhMbve52m"
      },
      "source": [
        "# Build ESPResSo\n",
        "%cd espresso\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake .. -DPYTHON=ON -DENABLE_PYTHON=ON -DCMAKE_INSTALL_PREFIX=../install\n",
        "!make -j2\n",
        "!make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/espresso/install/local/lib -name \"site-packages\""
      ],
      "metadata": {
        "id": "L-2yIA2kkdxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I4wi7Pce52m"
      },
      "source": [
        "# Add to Python path\n",
        "import sys\n",
        "sys.path.append(\"/content/espresso/install/local/lib/python3.11/dist-packages\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nOpoPkGzUB1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Diffusion of a polymer"
      ],
      "metadata": {
        "id": "XyRVn5gHrU23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Setting up the polymer and observables\n",
        "\n",
        "The first task is to compute the **average hydrodynamic radius** $R_h$, **end-to-end distance** $R_F$, and **radius of gyration** $R_g$ for different polymer lengths.  \n",
        "This will be achieved using the corresponding **observables**, described in the user guide under:\n",
        "\n",
        "> **Analysis → Direct analysis routines → Chains**\n",
        "\n",
        "---\n",
        "\n",
        "The second task is to estimate the **polymer diffusion coefficient** for different polymer lengths using two methods:\n",
        "\n",
        "1. The **center of mass mean squared displacement (MSD)** method (introduced earlier in this tutorial)  \n",
        "2. The **center of mass velocity autocorrelation method** (also known as the **Green–Kubo method**)\n",
        "\n",
        "To perform this analysis, we can again use the **multiple tau correlator**.\n",
        "\n",
        "---\n",
        "\n",
        "**Implementation Task:**  \n",
        "Write a function with the following signature:\n",
        "\n",
        "```python\n",
        "build_polymer(system, n_monomers, polymer_params, fene)\n"
      ],
      "metadata": {
        "id": "HwcMbk1XqgpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_polymer(system, n_monomers, polymer_params, fene):\n",
        "    positions = espressomd.polymer.linear_polymer_positions(\n",
        "        beads_per_chain=n_monomers, **polymer_params)\n",
        "    p_previous = None\n",
        "    for i, pos in enumerate(positions[0]):\n",
        "        p = system.part.add(pos=pos)\n",
        "        if p_previous is not None:\n",
        "            p.add_bond((fene, p_previous))\n",
        "        p_previous = p"
      ],
      "metadata": {
        "id": "mrrxJQKfVCTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correlator_msd(pids_monomers, tau_max):\n",
        "    com_pos = espressomd.observables.ComPosition(ids=pids_monomers)\n",
        "    com_pos_cor = espressomd.accumulators.Correlator(\n",
        "        obs1=com_pos, tau_lin=16, tau_max=tau_max, delta_N=5,\n",
        "        corr_operation=\"square_distance_componentwise\", compress1=\"discard1\")\n",
        "    return com_pos_cor\n",
        "\n",
        "\n",
        "def correlator_gk(pids_monomers, tau_max):\n",
        "    com_vel = espressomd.observables.ComVelocity(ids=pids_monomers)\n",
        "    com_vel_cor = espressomd.accumulators.Correlator(\n",
        "        obs1=com_vel, tau_lin=16, tau_max=tau_max, delta_N=10,\n",
        "        corr_operation=\"scalar_product\", compress1=\"discard1\")\n",
        "    return com_vel_cor"
      ],
      "metadata": {
        "id": "eVEVsbPZVFa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solvent_langevin(system, kT, gamma):\n",
        "    '''\n",
        "    Implicit solvation model based on Langevin dynamics (Rouse model).\n",
        "    '''\n",
        "    system.thermostat.set_langevin(kT=kT, gamma=gamma, seed=42)\n",
        "\n",
        "\n",
        "def solvent_lbm(system, kT, gamma):\n",
        "    '''\n",
        "    Lattice-based solvation model based on the LBM (Zimm model).\n",
        "    '''\n",
        "    lbf = espressomd.lb.LBFluidGPU(kT=kT, seed=42, agrid=1, dens=1,\n",
        "                                   visc=5, tau=system.time_step)\n",
        "    system.actors.add(lbf)\n",
        "    system.thermostat.set_lb(LB_fluid=lbf, gamma=gamma, seed=42)"
      ],
      "metadata": {
        "id": "4ovcWl6HfRUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Simulating the polymer"
      ],
      "metadata": {
        "id": "qj99O5M7qTS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import scipy.optimize\n",
        "\n",
        "import espressomd\n",
        "import espressomd.analyze\n",
        "import espressomd.accumulators\n",
        "import espressomd.observables\n",
        "import espressomd.polymer\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "espressomd.assert_features(['LENNARD_JONES'])\n",
        "\n",
        "# Setup constants\n",
        "BOX_L = 16\n",
        "TIME_STEP = 0.01\n",
        "LOOPS = 4000\n",
        "STEPS = 200\n",
        "KT = 1.0\n",
        "GAMMA = 5.0\n",
        "POLYMER_PARAMS = {'n_polymers': 1, 'bond_length': 1, 'seed': 42, 'min_distance': 0.9}\n",
        "POLYMER_MODEL = 'Rouse'\n",
        "assert POLYMER_MODEL in ('Rouse', 'Zimm')\n",
        "if POLYMER_MODEL == 'Zimm':\n",
        "    espressomd.assert_features(['CUDA'])\n",
        "    import espressomd.lb\n",
        "\n",
        "# System setup\n",
        "system = espressomd.System(box_l=3 * [BOX_L])\n",
        "system.cell_system.skin = 0.4\n",
        "\n",
        "# Lennard-Jones interaction\n",
        "system.non_bonded_inter[0, 0].lennard_jones.set_params(\n",
        "    epsilon=1.0, sigma=1.0, shift=\"auto\", cutoff=2.0**(1.0 / 6.0))\n",
        "\n",
        "# Fene interaction\n",
        "fene = espressomd.interactions.FeneBond(k=7, r_0=1, d_r_max=2)\n",
        "system.bonded_inter.add(fene)\n",
        "\n",
        "N_MONOMERS = [6,8,10,12,14]\n",
        "\n",
        "com_pos_tau_results = []\n",
        "com_pos_msd_results = []\n",
        "com_vel_tau_results = []\n",
        "com_vel_acf_results = []\n",
        "rh_results = []\n",
        "rf_results = []\n",
        "rg_results = []\n",
        "for index, N in enumerate(N_MONOMERS):\n",
        "    logging.info(f\"Polymer size: {N}\")\n",
        "    build_polymer(system, N, POLYMER_PARAMS, fene)\n",
        "\n",
        "    logging.info(\"Warming up the polymer chain.\")\n",
        "    system.time_step = 0.002\n",
        "    system.integrator.set_steepest_descent(\n",
        "        f_max=1.0,\n",
        "        gamma=10,\n",
        "        max_displacement=0.01)\n",
        "    system.integrator.run(2000)\n",
        "    system.integrator.set_vv()\n",
        "    logging.info(\"Warmup finished.\")\n",
        "\n",
        "    logging.info(\"Equilibration.\")\n",
        "    system.time_step = TIME_STEP\n",
        "    system.thermostat.set_langevin(kT=1.0, gamma=50, seed=42)\n",
        "    system.integrator.run(2000)\n",
        "    logging.info(\"Equilibration finished.\")\n",
        "\n",
        "    system.thermostat.turn_off()\n",
        "\n",
        "    if POLYMER_MODEL == 'Rouse':\n",
        "        solvent_langevin(system, KT, GAMMA)\n",
        "    elif POLYMER_MODEL == 'Zimm':\n",
        "        solvent_lbm(system, KT, GAMMA)\n",
        "\n",
        "    logging.info(\"Warming up the system with the fluid.\")\n",
        "    system.integrator.run(1000)\n",
        "    logging.info(\"Warming up the system with the fluid finished.\")\n",
        "\n",
        "    # configure MSD correlator\n",
        "    com_pos_cor = correlator_msd(np.arange(N), LOOPS * STEPS)\n",
        "    system.auto_update_accumulators.add(com_pos_cor)\n",
        "\n",
        "    # configure Green-Kubo correlator\n",
        "    com_vel_cor = correlator_gk(np.arange(N), LOOPS * STEPS)\n",
        "    system.auto_update_accumulators.add(com_vel_cor)\n",
        "\n",
        "    logging.info(\"Sampling started.\")\n",
        "    rhs = np.zeros(LOOPS)\n",
        "    rfs = np.zeros(LOOPS)\n",
        "    rgs = np.zeros(LOOPS)\n",
        "    for i in range(LOOPS):\n",
        "        system.integrator.run(STEPS)\n",
        "        rhs[i] = system.analysis.calc_rh(\n",
        "            chain_start=0,\n",
        "            number_of_chains=1,\n",
        "            chain_length=N)[0]\n",
        "        rfs[i] = system.analysis.calc_re(\n",
        "            chain_start=0,\n",
        "            number_of_chains=1,\n",
        "            chain_length=N)[0]\n",
        "        rgs[i] = system.analysis.calc_rg(\n",
        "            chain_start=0,\n",
        "            number_of_chains=1,\n",
        "            chain_length=N)[0]\n",
        "    logging.info(\"Sampling finished.\")\n",
        "\n",
        "    # store results\n",
        "    com_pos_cor.finalize()\n",
        "    com_pos_tau_results.append(com_pos_cor.lag_times())\n",
        "    com_pos_msd_results.append(np.sum(com_pos_cor.result(), axis=1))\n",
        "    com_vel_cor.finalize()\n",
        "    com_vel_tau_results.append(com_vel_cor.lag_times())\n",
        "    com_vel_acf_results.append(com_vel_cor.result())\n",
        "    rh_results.append(rhs)\n",
        "    rf_results.append(rfs)\n",
        "    rg_results.append(rgs)\n",
        "\n",
        "    # reset system\n",
        "    system.part.clear()\n",
        "    system.thermostat.turn_off()\n",
        "    system.actors.clear()\n",
        "    system.auto_update_accumulators.clear()\n",
        "\n",
        "rh_results = np.array(rh_results)\n",
        "rf_results = np.array(rf_results)\n",
        "rg_results = np.array(rg_results)\n",
        "com_pos_tau_results = np.array(com_pos_tau_results)\n",
        "com_pos_msd_results = np.reshape(com_pos_msd_results, [len(N_MONOMERS), -1])\n",
        "com_vel_tau_results = np.array(com_vel_tau_results)\n",
        "com_vel_acf_results = np.reshape(com_vel_acf_results, [len(N_MONOMERS), -1])"
      ],
      "metadata": {
        "id": "V9UdFC7-ewX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Data analysis\n",
        "We will calculate the means of time series with error bars obtained from the correlation-corrected standard error of the mean [5,6]."
      ],
      "metadata": {
        "id": "uaqJw-rAqH_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4RdH8QnplExf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "RK2rTD2tlHcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update({'font.size': 18})"
      ],
      "metadata": {
        "id": "lGE0Jh7YlJkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_error_mean_autocorrelation(time_series, variable_label):\n",
        "    '''\n",
        "    Calculate the mean and the correlation-corrected standard error\n",
        "    of the mean of time series by integrating the autocorrelation\n",
        "    function. See Janke 2002 [5] and Weigel, Janke 2010 [6].\n",
        "\n",
        "    Due to the short simulation length, it is not possible to fit an\n",
        "    exponential to the long-time tail. Instead, return a percentile.\n",
        "    '''\n",
        "    summary = []\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    for signal, N in zip(time_series, N_MONOMERS):\n",
        "        acf = espressomd.analyze.autocorrelation(signal - np.mean(signal))\n",
        "        # the acf cannot be integrated beyond tau=N/2\n",
        "        integral = np.array([acf[0] + 2 * np.sum(acf[1:j]) for j in np.arange(1, len(acf) // 2)])\n",
        "        # remove the noisy part of the integral\n",
        "        negative_number_list = np.nonzero(integral < 0)\n",
        "        if negative_number_list[0].size:\n",
        "            integral = integral[:int(0.95 * negative_number_list[0][0])]\n",
        "        # compute the standard error of the mean\n",
        "        std_err = np.sqrt(integral / acf.size)\n",
        "        # due to the small sample size, the long-time tail is not\n",
        "        # well resolved and cannot be fitted, so we use a percentile\n",
        "        asymptote = np.percentile(std_err, 75)\n",
        "        # plot the integral and asymptote\n",
        "        p = plt.plot([0, len(std_err)], 2 * [asymptote], '--')\n",
        "        plt.plot(np.arange(len(std_err)) + 1, std_err,\n",
        "                 '-', color=p[0].get_color(),\n",
        "                 label=rf'$\\int {variable_label}$ for N={N}')\n",
        "        summary.append((np.mean(signal), asymptote))\n",
        "    plt.xlabel(r'Lag time $\\tau / \\Delta t$')\n",
        "    plt.ylabel(rf'$\\int_{{-\\tau}}^{{+\\tau}} {variable_label}$')\n",
        "    plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return np.array(summary)\n",
        "\n",
        "\n",
        "def fitting_polymer_theory(polymer_model, n_monomers, diffusion, rh_exponent):\n",
        "    '''\n",
        "    Fit the appropriate polymer diffusion coefficient equation (Rouse or\n",
        "    Kirkwood-Zimm).\n",
        "    '''\n",
        "    def rouse(x, a):\n",
        "        return a / x\n",
        "\n",
        "    def kirkwood_zimm(x, a, b, exponent):\n",
        "        return a / x + b / x**exponent\n",
        "\n",
        "    x = np.linspace(min(n_monomers) - 0.5, max(n_monomers) + 0.5, 20)\n",
        "\n",
        "    if polymer_model == 'Rouse':\n",
        "        popt, _ = scipy.optimize.curve_fit(rouse, n_monomers, diffusion)\n",
        "        label = rf'$D^{{\\mathrm{{fit}}}} = \\frac{{{popt[0]:.2f}}}{{N}}$'\n",
        "        y = rouse(x, popt[0])\n",
        "    elif polymer_model == 'Zimm':\n",
        "        fitting_function = kirkwood_zimm\n",
        "        popt, _ = scipy.optimize.curve_fit(\n",
        "            lambda x, a, b: kirkwood_zimm(x, a, b, rh_exponent), n_monomers, diffusion)\n",
        "        y = kirkwood_zimm(x, popt[0], popt[1], rh_exponent)\n",
        "        label = f'''\\\n",
        "        $D^{{\\\\mathrm{{fit}}}} = \\\n",
        "            \\\\frac{{{popt[0]:.2f}}}{{N}} + \\\n",
        "            \\\\frac{{{popt[1] * 6 * np.pi:.3f} }}{{6\\\\pi}} \\\\cdot \\\n",
        "            \\\\frac{{{1}}}{{N^{{{rh_exponent:.2f}}}}}$ \\\n",
        "        '''\n",
        "    return x, y, label, popt"
      ],
      "metadata": {
        "id": "8vRNIT9ZlNYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3.1 Distance-based macromolecular properties\n",
        "\n",
        "How do  $R_h$, $R_g$, $R_F$, and the diffusion coefficient \\( D \\) depend on the number of monomers?  \n",
        "You can refer to the **Flory theory of polymers**, and assume you are simulating a real polymer in a good solvent, with Flory exponent \\( \\nu \\approx 0.588 \\).\n",
        "\n",
        "---\n",
        "\n",
        "**Task:**  \n",
        "Plot the end-to-end distance $R_F$ of the polymer as a function of the number of monomers.  \n",
        "What relation do you observe?\n",
        "\n",
        "---\n",
        "\n",
        "The end-to-end distance follows the scaling law:\n",
        "\n",
        "$$\n",
        "R_F = c_F N^{\\nu}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $R_F$ is the end-to-end distance,  \n",
        "- $c_F$ is a constant,  \n",
        "- $N$ is the number of monomers,  \n",
        "- $\\nu \\approx 0.588$ is the Flory exponent.\n"
      ],
      "metadata": {
        "id": "KAxiSH3un14q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_summary = standard_error_mean_autocorrelation(rf_results, r'\\operatorname{acf}(R_F)')\n",
        "rf_exponent, rf_prefactor = np.polyfit(np.log(N_MONOMERS), np.log(rf_summary[:, 0]), 1)\n",
        "rf_prefactor = np.exp(rf_prefactor)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "x = np.linspace(min(N_MONOMERS) - 0.5, max(N_MONOMERS) + 0.5, 20)\n",
        "plt.plot(x, rf_prefactor * x**rf_exponent, '-',\n",
        "         label=rf'$R_F^{{\\mathrm{{fit}}}} = {rf_prefactor:.2f} N^{{{rf_exponent:.2f}}}$')\n",
        "plt.errorbar(N_MONOMERS, rf_summary[:, 0],\n",
        "             yerr=rf_summary[:, 1],\n",
        "             ls='', marker='o', capsize=5, capthick=1,\n",
        "             label=r'$R_F^{\\mathrm{simulation}}$')\n",
        "plt.xlabel('Number of monomers $N$')\n",
        "plt.ylabel(r'End-to-end distance [$\\sigma$]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IZ5ML5RTlQWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the **radius of gyration** \\( R_g \\)  of the polymer as a function of the number of monomers.  \n",
        "What relation do you observe?\n",
        "\n",
        "---\n",
        "\n",
        "The radius of gyration follows the scaling law:\n",
        "\n",
        "$$\n",
        "R_g = c_g N^{\\nu}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- \\( R_g \\) is the radius of gyration,  \n",
        "- \\( c_g \\) is a constant,  \n",
        "- \\( N \\) is the number of monomers,  \n",
        "- \\( \\nu \\approx 0.588 \\) is the Flory exponent.\n"
      ],
      "metadata": {
        "id": "3h_F9gaGoJf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rg_summary = standard_error_mean_autocorrelation(rg_results, r'\\operatorname{acf}(R_g)')\n",
        "rg_exponent, rg_prefactor = np.polyfit(np.log(N_MONOMERS), np.log(rg_summary[:, 0]), 1)\n",
        "rg_prefactor = np.exp(rg_prefactor)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "x = np.linspace(min(N_MONOMERS) - 0.5, max(N_MONOMERS) + 0.5, 20)\n",
        "plt.plot(x, rg_prefactor * x**rg_exponent, '-',\n",
        "         label=rf'$R_g^{{\\mathrm{{fit}}}} = {rg_prefactor:.2f} N^{{{rg_exponent:.2f}}}$')\n",
        "plt.errorbar(N_MONOMERS, rg_summary[:, 0],\n",
        "             yerr=rg_summary[:, 1],\n",
        "             ls='', marker='o', capsize=5, capthick=1,\n",
        "             label=r'$R_g^{\\mathrm{simulation}}$')\n",
        "plt.xlabel('Number of monomers $N$')\n",
        "plt.ylabel(r'Radius of gyration [$\\sigma$]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BtvzMGrSlS2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For an **ideal polymer**, the relationship between the end-to-end distance and the radius of gyration is:\n",
        "\n",
        "$$\n",
        "\\frac{R_F^2}{R_g^2} = 6\n",
        "$$"
      ],
      "metadata": {
        "id": "wXRWDAIVomM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf2_rg2_ratio = rf_summary[:, 0]**2 / rg_summary[:, 0]**2\n",
        "print(np.around(rf2_rg2_ratio, 1))"
      ],
      "metadata": {
        "id": "-9LIdNy4lYsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the **hydrodynamic radius** \\( R_h \\) of the polymers as a function of the number of monomers.  \n",
        "What relation do you observe?\n",
        "\n",
        "---\n",
        "\n",
        "The hydrodynamic radius can be calculated via the **Stokes radius**, i.e., the radius of a sphere that diffuses at the same rate as the polymer.  \n",
        "An approximate formula is:\n",
        "\n",
        "$$\n",
        "R_h \\approx c_h N^{1/3}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- \\( R_h \\) is the hydrodynamic radius,  \n",
        "- \\( c_h \\) is a constant,  \n",
        "- \\( N \\) is the number of monomers.\n"
      ],
      "metadata": {
        "id": "Voj8d2Ehoxcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rh_summary = standard_error_mean_autocorrelation(rh_results, r'\\operatorname{acf}(R_h)')\n",
        "rh_exponent, rh_prefactor = np.polyfit(np.log(N_MONOMERS), np.log(rh_summary[:, 0]), 1)\n",
        "rh_prefactor = np.exp(rh_prefactor)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "x = np.linspace(min(N_MONOMERS) - 0.5, max(N_MONOMERS) + 0.5, 20)\n",
        "plt.plot(x, rh_prefactor * x**rh_exponent, '-',\n",
        "         label=rf'$R_h^{{\\mathrm{{fit}}}} = {rh_prefactor:.2f} N^{{{rh_exponent:.2f}}}$')\n",
        "plt.errorbar(N_MONOMERS, rh_summary[:, 0],\n",
        "             yerr=rh_summary[:, 1],\n",
        "             ls='', marker='o', capsize=5, capthick=1,\n",
        "             label=r'$R_h^{\\mathrm{simulation}}$')\n",
        "plt.xlabel('Number of monomers $N$')\n",
        "plt.ylabel(r'Hydrodynamic radius [$\\sigma$]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nN6SEvellbCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3.2 Diffusion coefficient using the MSD method\n",
        "\n",
        "Calculate the **diffusion coefficient** of the polymers using the **mean-squared displacement (MSD)**.\n",
        "\n",
        "---\n",
        "\n",
        "Recalling that for large \\( t \\), the diffusion coefficient \\( D \\) can be expressed as:\n",
        "\n",
        "$$\n",
        "6D = \\lim_{t \\to \\infty} \\frac{\\partial \\, \\text{MSD}(t)}{\\partial t}\n",
        "$$\n",
        "\n",
        "This is simply the **slope of the MSD** in the **diffusive regime**."
      ],
      "metadata": {
        "id": "rQMBBmOdo8JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cutoff for the diffusive regime (approximative)\n",
        "tau_f_index = 40\n",
        "# cutoff for the data series (larger lag times have larger variance due to undersampling)\n",
        "tau_max_index = 70\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.xlabel(r'$\\tau$ [$\\Delta t$]')\n",
        "plt.ylabel(r'MSD [$\\sigma^2$]')\n",
        "for index, (tau, msd) in enumerate(zip(com_pos_tau_results, com_pos_msd_results)):\n",
        "    plt.loglog(tau[1:120], msd[1:120], label=f'N={N_MONOMERS[index]}')\n",
        "plt.loglog(2 * [tau[tau_f_index]], [0, np.max(com_pos_msd_results)], '-', color='black')\n",
        "plt.text(tau[tau_f_index], np.max(com_pos_msd_results), r'$\\tau_{f}$')\n",
        "plt.loglog(2 * [tau[tau_max_index]], [0, np.max(com_pos_msd_results)], '-', color='black')\n",
        "plt.text(tau[tau_max_index], np.max(com_pos_msd_results), r'$\\tau_{max}$')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a7AGbDl-lfn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_msd = np.zeros(len(N_MONOMERS))\n",
        "plt.figure(figsize=(10, 8))\n",
        "weights = com_pos_cor.sample_sizes()\n",
        "for index, (tau, msd) in enumerate(zip(com_pos_tau_results, com_pos_msd_results)):\n",
        "    a, b = np.polyfit(tau[tau_f_index:tau_max_index], msd[tau_f_index:tau_max_index],\n",
        "                      1, w=weights[tau_f_index:tau_max_index])\n",
        "    x = np.array([tau[1], tau[tau_max_index - 1]])\n",
        "    p = plt.plot(x, a * x + b, '-')\n",
        "    plt.plot(tau[1:tau_max_index], msd[1:tau_max_index], 'o', color=p[0].get_color(),\n",
        "             label=rf'$N=${N_MONOMERS[index]}')\n",
        "    diffusion_msd[index] = a / 6\n",
        "plt.xlabel(r'$\\tau$ [$\\Delta t$]')\n",
        "plt.ylabel(r'MSD [$\\sigma^2$]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c8RKFu2Tljbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the dependence of the **diffusion coefficient** on the **hydrodynamic radius**.\n",
        "\n",
        "---\n",
        "\n",
        "Recall the formula for the diffusion coefficient of a short polymer in the **Kirkwood–Zimm model**:\n",
        "\n",
        "$$\n",
        "D = \\frac{D_0}{N} + \\frac{k_B T}{6 \\pi \\eta \\langle \\frac{1}{R_h} \\rangle}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $D$ is the polymer diffusion coefficient,  \n",
        "- $D_0 = \\frac{k_B T}{\\gamma} $ is the monomer diffusion coefficient,  \n",
        "- $\\gamma $ is the fluid friction coefficient,  \n",
        "- $\\eta $ is the fluid viscosity,  \n",
        "- $R_h $ is the hydrodynamic radius.\n",
        "\n",
        "For the **Rouse regime** (implicit solvent), the second term disappears.\n",
        "\n",
        "---\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- For the **Rouse regime**, use:  \n",
        "  $$\n",
        "  D = \\alpha N^{-1}\n",
        "  $$\n",
        "  and solve for $ \\alpha $.\n",
        "\n",
        "- For the **Zimm regime**, use:  \n",
        "  $$\n",
        "  D = \\frac{\\alpha_1}{N} + \\alpha_2 N^{-\\beta}\n",
        "  $$\n",
        "  where:\n",
        "  - $ \\beta $ is the **rh_exponent**,  \n",
        "  - Solve for $ \\alpha_1 $ and $ \\alpha_2 $.\n"
      ],
      "metadata": {
        "id": "f4dQoRiZpMcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "x, y, label, popt_msd = fitting_polymer_theory(POLYMER_MODEL, N_MONOMERS, diffusion_msd, rh_exponent)\n",
        "plt.plot(x, y, '-', label=label)\n",
        "plt.plot(N_MONOMERS, diffusion_msd, 'o', label=r'$D^{\\mathrm{simulation}}$')\n",
        "plt.xlabel('Number of monomers $N$')\n",
        "plt.ylabel(r'Diffusion coefficient [$\\sigma^2/t$]')\n",
        "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kLdzwCX3loxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.3 Diffusion coefficient using the Green–Kubo method\n",
        "\n",
        "Plot the **autocorrelation function (ACF)** and check that the decay is roughly **exponential**.\n",
        "\n",
        "---\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "Use the model:\n",
        "\n",
        "$$\n",
        "D = \\alpha e^{-\\beta \\tau}\n",
        "$$\n",
        "\n",
        "and solve for $ \\alpha $ and $ \\beta $.\n",
        "\n",
        "- You can **leave out the first data point** in the ACF if necessary.\n",
        "- Limit the fit to the **stable region within the first 20 data points**.\n"
      ],
      "metadata": {
        "id": "oBfGgA9opdnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential(x, a, b):\n",
        "    return a * np.exp(-b * x)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "for N, tau, acf in zip(N_MONOMERS, com_vel_tau_results, com_vel_acf_results):\n",
        "    popt, _ = scipy.optimize.curve_fit(exponential, tau[:20], acf[:20])\n",
        "    x = np.linspace(tau[0], tau[20 - 1], 100)\n",
        "    p = plt.plot(x, exponential(x, *popt), '-')\n",
        "    plt.plot(tau[:20], acf[:20], 'o',\n",
        "             color=p[0].get_color(), label=rf'$R(\\tau)$ for N = {N}')\n",
        "plt.xlabel(r'$\\tau$')\n",
        "plt.ylabel('Autocorrelation function')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KXBlu8ZElsFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Green–Kubo integral** for the diffusion coefficient takes the following form:\n",
        "\n",
        "$$\n",
        "D = \\frac{1}{3} \\int_0^{+\\infty} \\langle \\vec{v}_c(\\tau) \\cdot \\vec{v}_c(0) \\rangle \\, d\\tau\n",
        "$$\n",
        "\n",
        "Since our simulation is **finite in time**, we need to integrate up to a cutoff time \\( \\tau_{\\text{int}} \\).\n",
        "\n",
        "---\n",
        "\n",
        "To find the **optimal value** of $ \\tau_{\\text{int}} $:\n",
        "\n",
        "- Plot the integral as a function of $ \\tau_{\\text{int}} $.\n",
        "- Look for a **plateau region** in the plot.\n",
        "- This plateau is usually followed by **strong oscillations** caused by **low statistics** in the **long-time tail** of the autocorrelation function.\n"
      ],
      "metadata": {
        "id": "GwI1w9-YmL4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_gk = []\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "for N, tau, acf in zip(N_MONOMERS, com_vel_tau_results, com_vel_acf_results):\n",
        "    x = np.arange(2, 28)\n",
        "    y = [1 / 3 * np.trapz(acf[:j], tau[:j]) for j in x]\n",
        "    plt.plot(tau[x], y, label=rf'$D(\\tau_{{\\mathrm{{int}}}})$ for $N = {N}$')\n",
        "    diffusion_gk.append(np.mean(y[10:]))\n",
        "plt.xlabel(r'$\\tau_{\\mathrm{int}}$')\n",
        "plt.ylabel(r'$\\frac{1}{3} \\int_{\\tau=0}^{\\tau_{\\mathrm{int}}} \\left<\\vec{v_c}(\\tau)\\cdot\\vec{v_c}(0)\\right>\\, \\mathrm{d}\\tau$')\n",
        "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YjquYDrtlx2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 8))\n",
        "x, y, label, popt_gk = fitting_polymer_theory(POLYMER_MODEL, N_MONOMERS, diffusion_gk, rh_exponent)\n",
        "plt.plot(x, y, '-', label=label)\n",
        "plt.plot(N_MONOMERS, diffusion_gk, 'o', label=r'$D^{\\mathrm{simulation}}$')\n",
        "plt.xlabel('Number of monomers $N$')\n",
        "plt.ylabel(r'Diffusion coefficient [$\\sigma^2/t$]')\n",
        "plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p-kc0WUel1tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us compare the value of the diffusion coefficients calculated with the MSD and Green–Kubo methods:"
      ],
      "metadata": {
        "id": "EOvq1wrTl6rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'N\\tMSD\\t\\tGK\\t\\tdifference')\n",
        "for N, d_msd, d_gk in zip(N_MONOMERS, diffusion_msd, diffusion_gk):\n",
        "    print(f'{N}\\t{d_msd:.2e}\\t{d_gk:.2e}\\t{np.ceil(np.abs(d_msd-d_gk) * 100 / d_msd):.0f}%')"
      ],
      "metadata": {
        "id": "OzZaZgqSl5cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "[1] P. G. de Gennes. Scaling Concepts in Polymer Physics. Cornell University Press, Ithaca, NY, 1979.\n",
        "[2] M. Doi. Introduction to Polymer Physics. Clarendon Press, Oxford, 1996.\n",
        "[3] Michael Rubinstein and Ralph H. Colby. Polymer Physics. Oxford University Press, Oxford, UK, 2003. ISBN: 978-0-19-852059-7\n",
        "[4] Daan Frenkel and Berend Smit. Understanding Molecular Simulation, section 4.4.1. Academic Press, San Diego, second edition, 2002.\n",
        "[5] W. Janke, Statistical analysis of simulations: Data correlations and error estimation, Quantum Simulations of Complex Many-Body Systems: From Theory to Algorithms, Lecture Notes, J. Grotendorst, D. Marx, A. Muramatsu (Eds.), John von Neumann Institute for Computing, 10:423–445, 2002. https://www.physik.uni-leipzig.de/~janke/Paper/nic10_423_2002.pdf\n",
        "[6] M. Weigel, W. Janke, Error estimation and reduction with cross correlations, Phys. Rev. E, 81:066701, 2010, doi:10.1103/PhysRevE.81.066701; Erratum-ibid 81:069902, 2010, doi:10.1103/PhysRevE.81.069902."
      ],
      "metadata": {
        "id": "50Dzsc95p_Tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions?\n",
        "\n",
        "- what is autocorrleation function? Why we needes here to calculate different properties?\n",
        "\n",
        "- Can you describe the autocorrleation function profiles for the diffusion coefficient calculation?"
      ],
      "metadata": {
        "id": "GNMJdtXK3uJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Poiseuille flow in ESPResSo\n",
        "\n",
        "**2.1.1 Setting up the system**"
      ],
      "metadata": {
        "id": "ZeYAQK_bkoSx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFAmCf0xe52n"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import espressomd\n",
        "import espressomd.lb\n",
        "import espressomd.lbboundaries\n",
        "import espressomd.shapes\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "#espressomd.assert_features(['LB_BOUNDARIES_GPU'])\n",
        "\n",
        "# System constants\n",
        "BOX_L = 16.0\n",
        "TIME_STEP = 0.01\n",
        "\n",
        "#system = espressomd.System(box_l=[BOX_L] * 3)\n",
        "system.time_step = TIME_STEP\n",
        "system.cell_system.skin = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.2 Setting up the lattice-Boltzmann fluid**"
      ],
      "metadata": {
        "id": "bYLEKHVGk0io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LB parameters\n",
        "AGRID = 0.5\n",
        "VISCOSITY = 2.0\n",
        "FORCE_DENSITY = [0.0, 0.001, 0.0]\n",
        "DENSITY = 1.5\n",
        "\n",
        "# LB boundary parameters\n",
        "WALL_OFFSET = AGRID"
      ],
      "metadata": {
        "id": "jKfO5020UIIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"Setup LB fluid.\")\n",
        "lbf = espressomd.lb.LBFluid(agrid=AGRID, dens=DENSITY, visc=VISCOSITY, tau=TIME_STEP,\n",
        "                               ext_force_density=FORCE_DENSITY)\n",
        "system.actors.add(lbf)"
      ],
      "metadata": {
        "id": "b9dhlpfcUOn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a LB boundary and append it to the list of system LB boundaries."
      ],
      "metadata": {
        "id": "GSlc2NDulEjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"Setup LB boundaries.\")\n",
        "top_wall = espressomd.shapes.Wall(normal=[1, 0, 0], dist=WALL_OFFSET)\n",
        "bottom_wall = espressomd.shapes.Wall(normal=[-1, 0, 0], dist=-(BOX_L - WALL_OFFSET))\n",
        "\n",
        "top_boundary = espressomd.lbboundaries.LBBoundary(shape=top_wall)\n",
        "bottom_boundary = espressomd.lbboundaries.LBBoundary(shape=bottom_wall)\n",
        "\n",
        "system.lbboundaries.add(top_boundary)\n",
        "system.lbboundaries.add(bottom_boundary)"
      ],
      "metadata": {
        "id": "ba4D1ti0URG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.3. SimulationLinks to an external site.**\n",
        "We will now simulate the fluid flow until we reach the steady state."
      ],
      "metadata": {
        "id": "QaUfI2GUlJ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"Iterate until the flow profile converges (5000 LB updates).\")\n",
        "system.integrator.run(5000)"
      ],
      "metadata": {
        "id": "j8ChWNUgUUYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.4. Data analysisLinks to an external site.**\n",
        "We can now extract the flow profile and compare it to the analytical solution for the planar Poiseuille flow."
      ],
      "metadata": {
        "id": "zqhYPSMWlOXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Extract fluid velocity along the x-axis\n",
        "fluid_velocities = np.zeros((lbf.shape[0], 2))\n",
        "for x in range(lbf.shape[0]):\n",
        "    # Average over the node in y direction\n",
        "    v_tmp = np.zeros(lbf.shape[1])\n",
        "    for y in range(lbf.shape[1]):\n",
        "        v_tmp[y] = lbf[x, y, 0].velocity[1]\n",
        "    fluid_velocities[x, 0] = (x + 0.5) * AGRID\n",
        "    fluid_velocities[x, 1] = np.average(v_tmp)\n",
        "\n",
        "\n",
        "def poiseuille_flow(x, force_density, dynamic_viscosity, height):\n",
        "    return force_density / (2.0 * dynamic_viscosity) * \\\n",
        "        (height**2.0 / 4.0 - x**2.0)\n",
        "\n",
        "\n",
        "x_values = np.linspace(0.0, BOX_L, lbf.shape[0])\n",
        "HEIGHT = BOX_L - 2.0 * AGRID\n",
        "\n",
        "# Note that the LB viscosity is not the dynamic viscosity but the\n",
        "# kinematic viscosity (mu=LB_viscosity * density)\n",
        "plt.plot(\n",
        "    x_values,\n",
        "    poiseuille_flow(x_values - (HEIGHT / 2.0 + AGRID),\n",
        "                    FORCE_DENSITY[1],\n",
        "                    VISCOSITY * DENSITY,\n",
        "                    HEIGHT),\n",
        "    'o-',\n",
        "    label='analytical')\n",
        "plt.plot(fluid_velocities[:, 0], fluid_velocities[:, 1], label='simulation')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xr-A_VaBsFpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.5. Analysis for the report**\n",
        "Now in the figure you obtained from section 4, the simulated flow profile was compared against the analytical solution for the planar Poiseuille flow. Do you see they compared well?\n",
        "\n",
        "Now, save this graph and take note of the maximum velocity. Question: Where is the maximum velocity located and why is that?\n",
        "\n",
        "In section, 2.1.2, check the LB parameters used for the simulations. What would be the impact of changing some of those parameters such as viscosity and y-force constants? Can you change those values and show thir relationship with maximum velocity?"
      ],
      "metadata": {
        "id": "Kvoib8IClWcI"
      }
    }
  ]
}